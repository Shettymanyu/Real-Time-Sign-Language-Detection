Language barriers are very much still a real thing. 

We can take baby steps to help close that.

Speech to text and translators have made it a heap easier.

But what about for those that maybe don't speak or can't hear? 

What about them? 

Well...you can begin to use Tensorflow Object Detection and Python to help close that gap. And in this video, you'll learn how to take the first steps to doing just that! In this video, you'll learn how to build an end-to-end custom object detection model that allows you to translate sign language in real time. 

1. Collect images for deep learning using your webcam and OpenCV
2. Label images for sign language detection using LabelImg
3. Setup Tensorflow Object Detection pipeline configuration
4. Use transfer learning to train a deep learning model
5. Detect sign language in real time using OpenCV
 Thats it!

